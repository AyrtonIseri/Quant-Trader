{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import deque\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.nn_data_classifier import load_data, Classifier\n",
    "from utils.preprocess import preprocess, RNNDataset\n",
    "\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Price</th>\n",
       "      <th>Volume_ETH</th>\n",
       "      <th>Price_BTC</th>\n",
       "      <th>Volume_BTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2016-03-14 10:00:00</td>\n",
       "      <td>13.100</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>414.70</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2016-03-14 14:00:00</td>\n",
       "      <td>14.000</td>\n",
       "      <td>248.973956</td>\n",
       "      <td>414.95</td>\n",
       "      <td>9.077592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2016-03-14 19:00:00</td>\n",
       "      <td>14.750</td>\n",
       "      <td>8.442300</td>\n",
       "      <td>414.50</td>\n",
       "      <td>1.679111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>2016-03-15 00:00:00</td>\n",
       "      <td>12.650</td>\n",
       "      <td>651.351595</td>\n",
       "      <td>415.90</td>\n",
       "      <td>0.481963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>2016-03-15 01:00:00</td>\n",
       "      <td>12.576</td>\n",
       "      <td>4.558064</td>\n",
       "      <td>415.79</td>\n",
       "      <td>0.615654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903842</th>\n",
       "      <td>2022-11-12 16:00:00</td>\n",
       "      <td>1274.800</td>\n",
       "      <td>9.022555</td>\n",
       "      <td>16934.00</td>\n",
       "      <td>0.065520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903902</th>\n",
       "      <td>2022-11-12 17:00:00</td>\n",
       "      <td>1269.900</td>\n",
       "      <td>52.030265</td>\n",
       "      <td>16888.00</td>\n",
       "      <td>0.006411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903962</th>\n",
       "      <td>2022-11-12 18:00:00</td>\n",
       "      <td>1272.700</td>\n",
       "      <td>0.252397</td>\n",
       "      <td>16899.00</td>\n",
       "      <td>0.006868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904022</th>\n",
       "      <td>2022-11-12 19:00:00</td>\n",
       "      <td>1269.600</td>\n",
       "      <td>2.803365</td>\n",
       "      <td>16877.00</td>\n",
       "      <td>0.130167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904082</th>\n",
       "      <td>2022-11-12 20:00:00</td>\n",
       "      <td>1269.000</td>\n",
       "      <td>0.305341</td>\n",
       "      <td>16905.00</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50208 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time     Price  Volume_ETH  Price_BTC  Volume_BTC\n",
       "128     2016-03-14 10:00:00    13.100    0.008360     414.70    1.500000\n",
       "201     2016-03-14 14:00:00    14.000  248.973956     414.95    9.077592\n",
       "318     2016-03-14 19:00:00    14.750    8.442300     414.50    1.679111\n",
       "468     2016-03-15 00:00:00    12.650  651.351595     415.90    0.481963\n",
       "490     2016-03-15 01:00:00    12.576    4.558064     415.79    0.615654\n",
       "...                     ...       ...         ...        ...         ...\n",
       "2903842 2022-11-12 16:00:00  1274.800    9.022555   16934.00    0.065520\n",
       "2903902 2022-11-12 17:00:00  1269.900   52.030265   16888.00    0.006411\n",
       "2903962 2022-11-12 18:00:00  1272.700    0.252397   16899.00    0.006868\n",
       "2904022 2022-11-12 19:00:00  1269.600    2.803365   16877.00    0.130167\n",
       "2904082 2022-11-12 20:00:00  1269.000    0.305341   16905.00    0.022600\n",
       "\n",
       "[50208 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data = load_data()\n",
    "\n",
    "historical_data['minute'] = historical_data.time.dt.minute\n",
    "historical_data = historical_data[historical_data.minute == 0]\n",
    "historical_data.drop('minute', axis=1, inplace=True)\n",
    "\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Volume_ETH</th>\n",
       "      <th>Price_BTC</th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.100</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>414.70</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>14.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.000</td>\n",
       "      <td>248.973956</td>\n",
       "      <td>414.95</td>\n",
       "      <td>9.077592</td>\n",
       "      <td>14.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.750</td>\n",
       "      <td>8.442300</td>\n",
       "      <td>414.50</td>\n",
       "      <td>1.679111</td>\n",
       "      <td>12.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.650</td>\n",
       "      <td>651.351595</td>\n",
       "      <td>415.90</td>\n",
       "      <td>0.481963</td>\n",
       "      <td>12.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.576</td>\n",
       "      <td>4.558064</td>\n",
       "      <td>415.79</td>\n",
       "      <td>0.615654</td>\n",
       "      <td>12.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50202</th>\n",
       "      <td>1276.600</td>\n",
       "      <td>21.640138</td>\n",
       "      <td>16923.00</td>\n",
       "      <td>0.381346</td>\n",
       "      <td>1274.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50203</th>\n",
       "      <td>1274.800</td>\n",
       "      <td>9.022555</td>\n",
       "      <td>16934.00</td>\n",
       "      <td>0.065520</td>\n",
       "      <td>1269.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50204</th>\n",
       "      <td>1269.900</td>\n",
       "      <td>52.030265</td>\n",
       "      <td>16888.00</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>1272.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50205</th>\n",
       "      <td>1272.700</td>\n",
       "      <td>0.252397</td>\n",
       "      <td>16899.00</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>1269.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50206</th>\n",
       "      <td>1269.600</td>\n",
       "      <td>2.803365</td>\n",
       "      <td>16877.00</td>\n",
       "      <td>0.130167</td>\n",
       "      <td>1269.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50207 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Price  Volume_ETH  Price_BTC  Volume_BTC  Prediction\n",
       "0        13.100    0.008360     414.70    1.500000      14.000\n",
       "1        14.000  248.973956     414.95    9.077592      14.750\n",
       "2        14.750    8.442300     414.50    1.679111      12.650\n",
       "3        12.650  651.351595     415.90    0.481963      12.576\n",
       "4        12.576    4.558064     415.79    0.615654      12.662\n",
       "...         ...         ...        ...         ...         ...\n",
       "50202  1276.600   21.640138   16923.00    0.381346    1274.800\n",
       "50203  1274.800    9.022555   16934.00    0.065520    1269.900\n",
       "50204  1269.900   52.030265   16888.00    0.006411    1272.700\n",
       "50205  1272.700    0.252397   16899.00    0.006868    1269.600\n",
       "50206  1269.600    2.803365   16877.00    0.130167    1269.000\n",
       "\n",
       "[50207 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = historical_data.copy()\n",
    "time_outlook = 1\n",
    "data['Prediction'] = data.Price.shift(-time_outlook)\n",
    "data.dropna(inplace=True)\n",
    "data.drop('time', axis=1,inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60896/3134783768.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.array(dataset)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[array([[1.31000000e+01, 8.36000000e-03, 4.14700000e+02, 1.50000000e+00],\n",
       "               [1.40000000e+01, 2.48973956e+02, 4.14950000e+02, 9.07759197e+00],\n",
       "               [1.47500000e+01, 8.44230000e+00, 4.14500000e+02, 1.67911106e+00],\n",
       "               [1.26500000e+01, 6.51351595e+02, 4.15900000e+02, 4.81963470e-01],\n",
       "               [1.25760000e+01, 4.55806440e+00, 4.15790000e+02, 6.15654120e-01],\n",
       "               [1.26620000e+01, 8.92037234e+00, 4.18000000e+02, 1.47154553e+00],\n",
       "               [1.26300000e+01, 1.75970454e+00, 4.16710000e+02, 2.07328463e+00],\n",
       "               [1.30240000e+01, 1.75996693e+01, 4.15570000e+02, 1.85775689e+01],\n",
       "               [1.30390000e+01, 6.41923300e+00, 4.16160000e+02, 3.98193240e+00],\n",
       "               [1.26460000e+01, 2.00000000e+02, 4.15990000e+02, 3.87356600e-01],\n",
       "               [1.30000000e+01, 5.00000000e+00, 4.15720000e+02, 2.82285100e+00],\n",
       "               [1.33670000e+01, 2.59978869e+01, 4.14950000e+02, 1.61245856e+00],\n",
       "               [1.32910000e+01, 1.54732073e+01, 4.13960000e+02, 7.01000000e+00],\n",
       "               [1.36800000e+01, 4.23040000e+00, 4.17010000e+02, 3.87291430e-01],\n",
       "               [1.33320000e+01, 5.81287717e+01, 4.14990000e+02, 2.57997441e+00],\n",
       "               [1.28560000e+01, 3.71912924e+01, 4.17490000e+02, 7.45657721e+00],\n",
       "               [1.28000000e+01, 2.29880360e+01, 4.17400000e+02, 2.87472133e+00],\n",
       "               [1.25480000e+01, 1.00000000e+00, 4.17510000e+02, 9.74590000e+00],\n",
       "               [1.23870000e+01, 3.21149421e+01, 4.16840000e+02, 9.08740740e-01],\n",
       "               [1.18340000e+01, 1.96960000e-01, 4.18720000e+02, 1.20940700e+01],\n",
       "               [1.09240000e+01, 3.22321380e+01, 4.18210000e+02, 5.27438376e+00],\n",
       "               [1.07660000e+01, 8.04820732e+00, 4.18360000e+02, 6.03450012e+00],\n",
       "               [1.06350000e+01, 1.34780758e+01, 4.19670000e+02, 8.53348217e+00],\n",
       "               [1.12250000e+01, 2.76998517e+01, 4.18580000e+02, 4.97254052e+00]]),\n",
       "        8.834],\n",
       "       [array([[1.40000000e+01, 2.48973956e+02, 4.14950000e+02, 9.07759197e+00],\n",
       "               [1.47500000e+01, 8.44230000e+00, 4.14500000e+02, 1.67911106e+00],\n",
       "               [1.26500000e+01, 6.51351595e+02, 4.15900000e+02, 4.81963470e-01],\n",
       "               [1.25760000e+01, 4.55806440e+00, 4.15790000e+02, 6.15654120e-01],\n",
       "               [1.26620000e+01, 8.92037234e+00, 4.18000000e+02, 1.47154553e+00],\n",
       "               [1.26300000e+01, 1.75970454e+00, 4.16710000e+02, 2.07328463e+00],\n",
       "               [1.30240000e+01, 1.75996693e+01, 4.15570000e+02, 1.85775689e+01],\n",
       "               [1.30390000e+01, 6.41923300e+00, 4.16160000e+02, 3.98193240e+00],\n",
       "               [1.26460000e+01, 2.00000000e+02, 4.15990000e+02, 3.87356600e-01],\n",
       "               [1.30000000e+01, 5.00000000e+00, 4.15720000e+02, 2.82285100e+00],\n",
       "               [1.33670000e+01, 2.59978869e+01, 4.14950000e+02, 1.61245856e+00],\n",
       "               [1.32910000e+01, 1.54732073e+01, 4.13960000e+02, 7.01000000e+00],\n",
       "               [1.36800000e+01, 4.23040000e+00, 4.17010000e+02, 3.87291430e-01],\n",
       "               [1.33320000e+01, 5.81287717e+01, 4.14990000e+02, 2.57997441e+00],\n",
       "               [1.28560000e+01, 3.71912924e+01, 4.17490000e+02, 7.45657721e+00],\n",
       "               [1.28000000e+01, 2.29880360e+01, 4.17400000e+02, 2.87472133e+00],\n",
       "               [1.25480000e+01, 1.00000000e+00, 4.17510000e+02, 9.74590000e+00],\n",
       "               [1.23870000e+01, 3.21149421e+01, 4.16840000e+02, 9.08740740e-01],\n",
       "               [1.18340000e+01, 1.96960000e-01, 4.18720000e+02, 1.20940700e+01],\n",
       "               [1.09240000e+01, 3.22321380e+01, 4.18210000e+02, 5.27438376e+00],\n",
       "               [1.07660000e+01, 8.04820732e+00, 4.18360000e+02, 6.03450012e+00],\n",
       "               [1.06350000e+01, 1.34780758e+01, 4.19670000e+02, 8.53348217e+00],\n",
       "               [1.12250000e+01, 2.76998517e+01, 4.18580000e+02, 4.97254052e+00],\n",
       "               [8.83400000e+00, 2.00000000e+00, 4.13600000e+02, 3.04694581e+00]]),\n",
       "        9.12],\n",
       "       [array([[1.47500000e+01, 8.44230000e+00, 4.14500000e+02, 1.67911106e+00],\n",
       "               [1.26500000e+01, 6.51351595e+02, 4.15900000e+02, 4.81963470e-01],\n",
       "               [1.25760000e+01, 4.55806440e+00, 4.15790000e+02, 6.15654120e-01],\n",
       "               [1.26620000e+01, 8.92037234e+00, 4.18000000e+02, 1.47154553e+00],\n",
       "               [1.26300000e+01, 1.75970454e+00, 4.16710000e+02, 2.07328463e+00],\n",
       "               [1.30240000e+01, 1.75996693e+01, 4.15570000e+02, 1.85775689e+01],\n",
       "               [1.30390000e+01, 6.41923300e+00, 4.16160000e+02, 3.98193240e+00],\n",
       "               [1.26460000e+01, 2.00000000e+02, 4.15990000e+02, 3.87356600e-01],\n",
       "               [1.30000000e+01, 5.00000000e+00, 4.15720000e+02, 2.82285100e+00],\n",
       "               [1.33670000e+01, 2.59978869e+01, 4.14950000e+02, 1.61245856e+00],\n",
       "               [1.32910000e+01, 1.54732073e+01, 4.13960000e+02, 7.01000000e+00],\n",
       "               [1.36800000e+01, 4.23040000e+00, 4.17010000e+02, 3.87291430e-01],\n",
       "               [1.33320000e+01, 5.81287717e+01, 4.14990000e+02, 2.57997441e+00],\n",
       "               [1.28560000e+01, 3.71912924e+01, 4.17490000e+02, 7.45657721e+00],\n",
       "               [1.28000000e+01, 2.29880360e+01, 4.17400000e+02, 2.87472133e+00],\n",
       "               [1.25480000e+01, 1.00000000e+00, 4.17510000e+02, 9.74590000e+00],\n",
       "               [1.23870000e+01, 3.21149421e+01, 4.16840000e+02, 9.08740740e-01],\n",
       "               [1.18340000e+01, 1.96960000e-01, 4.18720000e+02, 1.20940700e+01],\n",
       "               [1.09240000e+01, 3.22321380e+01, 4.18210000e+02, 5.27438376e+00],\n",
       "               [1.07660000e+01, 8.04820732e+00, 4.18360000e+02, 6.03450012e+00],\n",
       "               [1.06350000e+01, 1.34780758e+01, 4.19670000e+02, 8.53348217e+00],\n",
       "               [1.12250000e+01, 2.76998517e+01, 4.18580000e+02, 4.97254052e+00],\n",
       "               [8.83400000e+00, 2.00000000e+00, 4.13600000e+02, 3.04694581e+00],\n",
       "               [9.12000000e+00, 5.00000000e-01, 4.13750000e+02, 2.53076796e+01]]),\n",
       "        9.993],\n",
       "       ...,\n",
       "       [array([[1.27860000e+03, 1.12300465e+01, 1.69270000e+04, 2.29899360e+00],\n",
       "               [1.26230000e+03, 5.46728700e+00, 1.68070000e+04, 3.63972110e+00],\n",
       "               [1.27400000e+03, 4.51215220e-01, 1.68550000e+04, 6.69562300e-02],\n",
       "               [1.24840000e+03, 1.14151467e+01, 1.66530000e+04, 2.08969745e+00],\n",
       "               [1.27040000e+03, 2.71409692e+00, 1.68100000e+04, 6.26076720e-01],\n",
       "               [1.27840000e+03, 1.86915590e-01, 1.69110000e+04, 1.01823390e-01],\n",
       "               [1.28610000e+03, 2.24955679e+00, 1.70470000e+04, 7.34646349e+00],\n",
       "               [1.27460000e+03, 2.91878500e-01, 1.68790000e+04, 1.40152041e+00],\n",
       "               [1.27200000e+03, 4.87888070e+00, 1.68740000e+04, 6.66759800e-02],\n",
       "               [1.27690000e+03, 2.56855870e-01, 1.68960000e+04, 1.25475000e-02],\n",
       "               [1.25900000e+03, 2.92416531e+00, 1.69120000e+04, 8.61133000e-03],\n",
       "               [1.25440000e+03, 2.94691442e+01, 1.67270000e+04, 7.33723340e-01],\n",
       "               [1.24490000e+03, 3.98147196e+00, 1.66810000e+04, 1.36564280e-01],\n",
       "               [1.26210000e+03, 2.77273734e+00, 1.67600000e+04, 2.67736300e-02],\n",
       "               [1.26620000e+03, 2.56051960e-01, 1.68170000e+04, 1.35676810e+00],\n",
       "               [1.26200000e+03, 5.86644220e-01, 1.68330000e+04, 1.14727800e-02],\n",
       "               [1.26280000e+03, 1.07567162e+00, 1.68740000e+04, 3.96966400e-02],\n",
       "               [1.26140000e+03, 1.92691071e+00, 1.68630000e+04, 5.17262520e-01],\n",
       "               [1.26200000e+03, 1.55521998e+01, 1.68850000e+04, 3.87818600e-02],\n",
       "               [1.26700000e+03, 1.64113670e+01, 1.68660000e+04, 2.55122650e-01],\n",
       "               [1.26510000e+03, 1.90511944e+00, 1.68510000e+04, 1.61495960e-01],\n",
       "               [1.27660000e+03, 2.16401379e+01, 1.69230000e+04, 3.81346100e-01],\n",
       "               [1.27480000e+03, 9.02255517e+00, 1.69340000e+04, 6.55204800e-02],\n",
       "               [1.26990000e+03, 5.20302653e+01, 1.68880000e+04, 6.41126000e-03]]),\n",
       "        1272.7],\n",
       "       [array([[1.26230000e+03, 5.46728700e+00, 1.68070000e+04, 3.63972110e+00],\n",
       "               [1.27400000e+03, 4.51215220e-01, 1.68550000e+04, 6.69562300e-02],\n",
       "               [1.24840000e+03, 1.14151467e+01, 1.66530000e+04, 2.08969745e+00],\n",
       "               [1.27040000e+03, 2.71409692e+00, 1.68100000e+04, 6.26076720e-01],\n",
       "               [1.27840000e+03, 1.86915590e-01, 1.69110000e+04, 1.01823390e-01],\n",
       "               [1.28610000e+03, 2.24955679e+00, 1.70470000e+04, 7.34646349e+00],\n",
       "               [1.27460000e+03, 2.91878500e-01, 1.68790000e+04, 1.40152041e+00],\n",
       "               [1.27200000e+03, 4.87888070e+00, 1.68740000e+04, 6.66759800e-02],\n",
       "               [1.27690000e+03, 2.56855870e-01, 1.68960000e+04, 1.25475000e-02],\n",
       "               [1.25900000e+03, 2.92416531e+00, 1.69120000e+04, 8.61133000e-03],\n",
       "               [1.25440000e+03, 2.94691442e+01, 1.67270000e+04, 7.33723340e-01],\n",
       "               [1.24490000e+03, 3.98147196e+00, 1.66810000e+04, 1.36564280e-01],\n",
       "               [1.26210000e+03, 2.77273734e+00, 1.67600000e+04, 2.67736300e-02],\n",
       "               [1.26620000e+03, 2.56051960e-01, 1.68170000e+04, 1.35676810e+00],\n",
       "               [1.26200000e+03, 5.86644220e-01, 1.68330000e+04, 1.14727800e-02],\n",
       "               [1.26280000e+03, 1.07567162e+00, 1.68740000e+04, 3.96966400e-02],\n",
       "               [1.26140000e+03, 1.92691071e+00, 1.68630000e+04, 5.17262520e-01],\n",
       "               [1.26200000e+03, 1.55521998e+01, 1.68850000e+04, 3.87818600e-02],\n",
       "               [1.26700000e+03, 1.64113670e+01, 1.68660000e+04, 2.55122650e-01],\n",
       "               [1.26510000e+03, 1.90511944e+00, 1.68510000e+04, 1.61495960e-01],\n",
       "               [1.27660000e+03, 2.16401379e+01, 1.69230000e+04, 3.81346100e-01],\n",
       "               [1.27480000e+03, 9.02255517e+00, 1.69340000e+04, 6.55204800e-02],\n",
       "               [1.26990000e+03, 5.20302653e+01, 1.68880000e+04, 6.41126000e-03],\n",
       "               [1.27270000e+03, 2.52396630e-01, 1.68990000e+04, 6.86814000e-03]]),\n",
       "        1269.6],\n",
       "       [array([[1.27400000e+03, 4.51215220e-01, 1.68550000e+04, 6.69562300e-02],\n",
       "               [1.24840000e+03, 1.14151467e+01, 1.66530000e+04, 2.08969745e+00],\n",
       "               [1.27040000e+03, 2.71409692e+00, 1.68100000e+04, 6.26076720e-01],\n",
       "               [1.27840000e+03, 1.86915590e-01, 1.69110000e+04, 1.01823390e-01],\n",
       "               [1.28610000e+03, 2.24955679e+00, 1.70470000e+04, 7.34646349e+00],\n",
       "               [1.27460000e+03, 2.91878500e-01, 1.68790000e+04, 1.40152041e+00],\n",
       "               [1.27200000e+03, 4.87888070e+00, 1.68740000e+04, 6.66759800e-02],\n",
       "               [1.27690000e+03, 2.56855870e-01, 1.68960000e+04, 1.25475000e-02],\n",
       "               [1.25900000e+03, 2.92416531e+00, 1.69120000e+04, 8.61133000e-03],\n",
       "               [1.25440000e+03, 2.94691442e+01, 1.67270000e+04, 7.33723340e-01],\n",
       "               [1.24490000e+03, 3.98147196e+00, 1.66810000e+04, 1.36564280e-01],\n",
       "               [1.26210000e+03, 2.77273734e+00, 1.67600000e+04, 2.67736300e-02],\n",
       "               [1.26620000e+03, 2.56051960e-01, 1.68170000e+04, 1.35676810e+00],\n",
       "               [1.26200000e+03, 5.86644220e-01, 1.68330000e+04, 1.14727800e-02],\n",
       "               [1.26280000e+03, 1.07567162e+00, 1.68740000e+04, 3.96966400e-02],\n",
       "               [1.26140000e+03, 1.92691071e+00, 1.68630000e+04, 5.17262520e-01],\n",
       "               [1.26200000e+03, 1.55521998e+01, 1.68850000e+04, 3.87818600e-02],\n",
       "               [1.26700000e+03, 1.64113670e+01, 1.68660000e+04, 2.55122650e-01],\n",
       "               [1.26510000e+03, 1.90511944e+00, 1.68510000e+04, 1.61495960e-01],\n",
       "               [1.27660000e+03, 2.16401379e+01, 1.69230000e+04, 3.81346100e-01],\n",
       "               [1.27480000e+03, 9.02255517e+00, 1.69340000e+04, 6.55204800e-02],\n",
       "               [1.26990000e+03, 5.20302653e+01, 1.68880000e+04, 6.41126000e-03],\n",
       "               [1.27270000e+03, 2.52396630e-01, 1.68990000e+04, 6.86814000e-03],\n",
       "               [1.26960000e+03, 2.80336453e+00, 1.68770000e+04, 1.30167280e-01]]),\n",
       "        1269.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "sequence = deque(maxlen=SEQ_LEN)\n",
    "y = data.Prediction\n",
    "X = data.drop('Prediction', axis=1)\n",
    "\n",
    "for seq, price in zip(X.values, y):\n",
    "    sequence.append(seq)\n",
    "    length = len(sequence)\n",
    "\n",
    "    if length == SEQ_LEN:\n",
    "        new_seq = np.array(sequence)\n",
    "        entry = [new_seq, price]\n",
    "        dataset.append([new_seq, price])\n",
    "dataset = np.array(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredDataSet(Dataset):\n",
    "    def __init__(self, data: np.array, transform = None, target_transform = None):\n",
    "        self._data = data\n",
    "        self._transform = transform\n",
    "        self._target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, x:int):\n",
    "        X = torch.tensor(self._data[x][0])\n",
    "        y = torch.tensor(self._data[x][1])\n",
    "        return X.float(), y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(dataset)\n",
    "training_size = int(0.6 * total_len)\n",
    "validation_size = int(0.2 * total_len)\n",
    "testing_size = int(0.2 * total_len)\n",
    "\n",
    "train_df = dataset[:training_size]\n",
    "validation_df = dataset[training_size:training_size+validation_size]\n",
    "testing_df = dataset[-testing_size:]\n",
    "\n",
    "training = PredDataSet(train_df)\n",
    "validation = PredDataSet(validation_df)\n",
    "testing = PredDataSet(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class RNN_module(nn.Module):\n",
    "    def __init__(self, hidden_size, input_size, num_layers):\n",
    "        super(RNN_module, self).__init__()\n",
    "        self._num_layers = num_layers\n",
    "        self._input_size = input_size\n",
    "        self._hidden_size = hidden_size\n",
    "        self._output_size = 1\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = self._input_size, hidden_size = self._hidden_size, \n",
    "                            num_layers = self._num_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(in_features=self._hidden_size, out_features= self._output_size)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"RNN LSTM Model w/ {self._input_size} features and {self._num_layers} layers and {self._hidden_size} of hidden size\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        lstm_output, (h_n, c_n) = self.lstm(input)\n",
    "        pred = self.fc(lstm_output[:, -1, :])\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "learning_rate = 0.01\n",
    "dim_size = training[0][0].shape[1]\n",
    "hidden_size = 60\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "layers = 1\n",
    "\n",
    "train_dataloader = DataLoader(training, batch_size = batch_size, shuffle = True)\n",
    "validation_dataloader = DataLoader(validation, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(testing, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "model = RNN_module(hidden_size = hidden_size, input_size = dim_size,\n",
    "                   num_layers = layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = './models_parameters/LSTM/checkpoints_2/'\n",
    "BEST_PATH = './models_parameters/LSTM/best_model.pth'\n",
    "\n",
    "def epoch_training(model, train_dataloader, criterion, epoch, total_epochs, optimizer):\n",
    "    n_of_steps = len(train_dataloader)\n",
    "    running_loss = 0\n",
    "\n",
    "    for current_batch, (sequence, prices) in enumerate(train_dataloader):\n",
    "        #forward: we are calculating the loss given the parameters\n",
    "        outputs = model(sequence).view(-1)\n",
    "        loss = criterion(input=outputs, target = prices)\n",
    "\n",
    "        #backward: lets update the parameters given the current loss\n",
    "        optimizer.zero_grad() #nullifies the current gradients. If you don't do this, gradients will be added up (you don't want that)\n",
    "        loss.backward() #computates the bwrd-prop gradient for each model parameter\n",
    "        optimizer.step() #updates the model current parameter using the gradients.\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (current_batch + 1) % 50 == 0:\n",
    "            print(f\"epoch {epoch+1}/{total_epochs}, current step(batch): {current_batch+1}/{n_of_steps}, loss = {loss.item():.4f} \")\n",
    "            writer.add_scalar('training loss: ', running_loss/50, epoch * n_of_steps + current_batch)\n",
    "            running_loss = 0\n",
    "            \n",
    "    writer.add_scalar('Epoch loss: ', loss, epoch + 1)\n",
    "\n",
    "\n",
    "def epoch_validate(model, validation_dataloader, criterion, epoch, total_epochs):\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        total_loss = 0\n",
    "        for current_batch, (sequence, prices) in enumerate(validation_dataloader):\n",
    "\n",
    "            #forward: we are calculating the loss given the parameters\n",
    "            outputs = model(sequence).view(-1)\n",
    "            loss = criterion(input=outputs, target = prices).item()\n",
    "\n",
    "            batch_size = outputs.shape[0]\n",
    "            loss *= batch_size\n",
    "            total_loss += loss\n",
    "            n_samples += batch_size\n",
    "\n",
    "        final_loss = total_loss / n_samples\n",
    "\n",
    "        print(f\"epoch {epoch+1}/{total_epochs} final_loss: {final_loss}\")\n",
    "        writer.add_scalar('Validation Accuracy: ', final_loss, epoch+1)\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def train_loop(model: RNN_module, train_dataloader: DataLoader, criterion: torch.nn, validation_dataloader: DataLoader, epochs: int, optimizer: torch.optim):\n",
    "    \n",
    "    max_precision = 0\n",
    "    is_best = False\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_training(model, train_dataloader, criterion, epoch, epochs, optimizer)\n",
    "\n",
    "        precision = epoch_validate(model, validation_dataloader, criterion, epoch, epochs)\n",
    "\n",
    "        if precision < max_precision:\n",
    "            is_best = True\n",
    "            max_precision = precision\n",
    "        else:\n",
    "            is_best = False\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optim_state': optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "        if is_best:\n",
    "            torch.save(checkpoint, BEST_PATH)\n",
    "        \n",
    "        torch.save(checkpoint, CHECKPOINT_PATH+f'model_{epoch+1}.pth')\n",
    "\n",
    "def overfit_batch(model: RNN_module, train_dataloader: DataLoader, criterion: torch.nn, validation_dataloader: DataLoader, epochs: int, optimizer: torch.optim):\n",
    "    \n",
    "    sequence, prices = next(iter(train_dataloader))\n",
    "    running_loss = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        n_of_steps = len(prices)\n",
    "        \n",
    "        #forward: we are calculating the loss given the parameters\n",
    "        outputs = model(sequence).view(-1)\n",
    "        loss = criterion(input=outputs, target = prices)\n",
    "\n",
    "        #backward: lets update the parameters given the current loss\n",
    "        optimizer.zero_grad() #nullifies the current gradients. If you don't do this, gradients will be added up (you don't want that)\n",
    "        loss.backward() #computates the bwrd-prop gradient for each model parameter\n",
    "        optimizer.step() #updates the model current parameter using the gradients.\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"epoch {epoch+1}/{epochs}, loss = {loss.item():.4f} \")\n",
    "            writer.add_scalar('training loss: ', running_loss/100, epoch * n_of_steps)\n",
    "            running_loss = 0\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_dataloader: DataLoader, model: nn.Module):\n",
    "    with torch.no_grad():\n",
    "        n_corrects = 0\n",
    "        n_samples = 0\n",
    "\n",
    "        for current_batch, (sequence, label) in enumerate(test_dataloader):\n",
    "            #forward: we are calculating the loss given the parameters\n",
    "            outputs = model(sequence)\n",
    "            predictions = torch.argmax(outputs, 1)\n",
    "\n",
    "            n_samples += outputs.shape[0]\n",
    "            n_corrects += (predictions == label).sum().item()\n",
    "\n",
    "            if (current_batch + 1) % 200 == 0:\n",
    "                print(f\"test batch: {current_batch+1}/{len(test_dataloader)}, current accuracy: {100 * n_corrects / n_samples}\")\n",
    "\n",
    "        acc = 100.0 * n_corrects / n_samples\n",
    "        print(f\"final test accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100/10000, loss = 105710.3203 \n",
      "epoch 200/10000, loss = 94911.7344 \n",
      "epoch 300/10000, loss = 84946.8359 \n",
      "epoch 400/10000, loss = 76505.4922 \n",
      "epoch 500/10000, loss = 69261.5156 \n",
      "epoch 600/10000, loss = 63060.6172 \n",
      "epoch 700/10000, loss = 57784.7031 \n",
      "epoch 800/10000, loss = 53330.8047 \n",
      "epoch 900/10000, loss = 49604.9922 \n",
      "epoch 1000/10000, loss = 46520.0234 \n",
      "epoch 1100/10000, loss = 43994.4648 \n",
      "epoch 1200/10000, loss = 41952.4258 \n",
      "epoch 1300/10000, loss = 40323.5234 \n",
      "epoch 1400/10000, loss = 39043.0898 \n",
      "epoch 1500/10000, loss = 38052.3438 \n",
      "epoch 1600/10000, loss = 37298.5586 \n",
      "epoch 1700/10000, loss = 36735.2578 \n",
      "epoch 1800/10000, loss = 36322.1289 \n",
      "epoch 1900/10000, loss = 36024.9766 \n",
      "epoch 2000/10000, loss = 35815.3984 \n",
      "epoch 2100/10000, loss = 35670.4102 \n",
      "epoch 2200/10000, loss = 35571.8398 \n",
      "epoch 2300/10000, loss = 35505.7578 \n",
      "epoch 2400/10000, loss = 35461.7852 \n",
      "epoch 2500/10000, loss = 35432.4102 \n",
      "epoch 2600/10000, loss = 35412.4062 \n",
      "epoch 2700/10000, loss = 35398.2188 \n",
      "epoch 2800/10000, loss = 35387.5273 \n",
      "epoch 2900/10000, loss = 35378.8828 \n",
      "epoch 3000/10000, loss = 35371.3984 \n",
      "epoch 3100/10000, loss = 35364.5586 \n",
      "epoch 3200/10000, loss = 35358.0820 \n",
      "epoch 3300/10000, loss = 35351.7969 \n",
      "epoch 3400/10000, loss = 35345.6250 \n",
      "epoch 3500/10000, loss = 35339.5273 \n",
      "epoch 3600/10000, loss = 35333.4805 \n",
      "epoch 3700/10000, loss = 35327.4648 \n",
      "epoch 3800/10000, loss = 35321.4727 \n",
      "epoch 3900/10000, loss = 35315.5117 \n",
      "epoch 4000/10000, loss = 35309.5586 \n",
      "epoch 4100/10000, loss = 35303.6250 \n",
      "epoch 4200/10000, loss = 35297.6992 \n",
      "epoch 4300/10000, loss = 35291.7812 \n",
      "epoch 4400/10000, loss = 35285.8633 \n",
      "epoch 4500/10000, loss = 35279.9531 \n",
      "epoch 4600/10000, loss = 35274.0352 \n",
      "epoch 4700/10000, loss = 35268.1172 \n",
      "epoch 4800/10000, loss = 35262.1914 \n",
      "epoch 4900/10000, loss = 35256.2656 \n",
      "epoch 5000/10000, loss = 35250.3242 \n",
      "epoch 5100/10000, loss = 35244.3672 \n",
      "epoch 5200/10000, loss = 35238.3984 \n",
      "epoch 5300/10000, loss = 35232.4141 \n",
      "epoch 5400/10000, loss = 35226.4102 \n",
      "epoch 5500/10000, loss = 35220.3828 \n",
      "epoch 5600/10000, loss = 35214.3398 \n",
      "epoch 5700/10000, loss = 35208.2656 \n",
      "epoch 5800/10000, loss = 35202.1680 \n",
      "epoch 5900/10000, loss = 35196.0469 \n",
      "epoch 6000/10000, loss = 35189.8867 \n",
      "epoch 6100/10000, loss = 35183.7070 \n",
      "epoch 6200/10000, loss = 35177.4883 \n",
      "epoch 6300/10000, loss = 35171.2305 \n",
      "epoch 6400/10000, loss = 35164.9414 \n",
      "epoch 6500/10000, loss = 35158.6133 \n",
      "epoch 6600/10000, loss = 35152.2500 \n",
      "epoch 6700/10000, loss = 35145.8359 \n",
      "epoch 6800/10000, loss = 35139.3828 \n",
      "epoch 6900/10000, loss = 35132.8867 \n",
      "epoch 7000/10000, loss = 35126.3516 \n",
      "epoch 7100/10000, loss = 35119.7656 \n",
      "epoch 7200/10000, loss = 35113.1289 \n",
      "epoch 7300/10000, loss = 35106.4531 \n",
      "epoch 7400/10000, loss = 35099.7188 \n",
      "epoch 7500/10000, loss = 35092.9414 \n",
      "epoch 7600/10000, loss = 35086.1133 \n",
      "epoch 7700/10000, loss = 35079.2344 \n",
      "epoch 7800/10000, loss = 35072.3086 \n",
      "epoch 7900/10000, loss = 35065.3359 \n",
      "epoch 8000/10000, loss = 35058.3125 \n",
      "epoch 8100/10000, loss = 35051.2383 \n",
      "epoch 8200/10000, loss = 35044.1250 \n",
      "epoch 8300/10000, loss = 35036.9570 \n",
      "epoch 8400/10000, loss = 35029.7500 \n",
      "epoch 8500/10000, loss = 35022.5000 \n",
      "epoch 8600/10000, loss = 35015.2109 \n",
      "epoch 8700/10000, loss = 35007.8828 \n",
      "epoch 8800/10000, loss = 35000.5195 \n",
      "epoch 8900/10000, loss = 34993.1250 \n",
      "epoch 9000/10000, loss = 34985.6992 \n",
      "epoch 9100/10000, loss = 34978.2461 \n",
      "epoch 9200/10000, loss = 34970.7734 \n",
      "epoch 9300/10000, loss = 34963.2773 \n",
      "epoch 9400/10000, loss = 34955.7656 \n",
      "epoch 9500/10000, loss = 34948.2422 \n",
      "epoch 9600/10000, loss = 34940.7109 \n",
      "epoch 9700/10000, loss = 34933.1797 \n",
      "epoch 9800/10000, loss = 34925.6406 \n",
      "epoch 9900/10000, loss = 34918.1094 \n",
      "epoch 10000/10000, loss = 34910.5859 \n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "overfit_batch(model, train_dataloader=train_dataloader, criterion=criterion, validation_dataloader = validation_dataloader, epochs=epochs, optimizer=optimizer)\n",
    "# train_loop(model, train_dataloader=train_dataloader, criterion=criterion, validation_dataloader = validation_dataloader, epochs=epochs, optimizer=optimizer)\n",
    "# test_loop(test_dataloader=test_dataloader, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "gradient:\n",
      "----------\n",
      "<bound method Tensor.norm of tensor([[-3.9372e-33, -1.5202e-33, -2.0430e-31, -8.6199e-34],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.0891e-28,  1.3080e-27,  3.1140e-26,  6.3675e-28],\n",
      "        [ 4.7624e-28,  3.7155e-26,  2.5959e-26,  3.1659e-29],\n",
      "        [-6.8102e-28, -1.4144e-28, -3.5121e-26, -1.7453e-28],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.2524e-38,  3.2859e-36,  2.2272e-36,  1.2228e-38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.1323e-15,  9.7263e-16,  1.6381e-13,  1.1995e-15],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.2036e-18, -1.8455e-19, -1.1274e-16, -4.6138e-21],\n",
      "        [-9.1837e-34,  5.5154e-33, -4.8145e-32, -5.7267e-33],\n",
      "        [ 4.8715e-24,  1.5065e-22,  2.5049e-22,  9.6578e-26],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.5213e-20,  6.6280e-21,  3.8479e-18,  1.6502e-22],\n",
      "        [-1.5401e-24, -1.8157e-24, -8.0095e-23, -6.8142e-25],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.5926e-26, -2.3697e-27, -1.3264e-24, -5.8835e-29],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.3375e-20,  2.5831e-18,  1.7554e-18,  9.1789e-21],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6195e-25,  2.5383e-27,  8.4430e-24,  6.0280e-25],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.0693e-16, -2.5706e-17, -1.5703e-14, -6.4265e-19],\n",
      "        [-1.7845e-21, -8.1989e-19, -9.1160e-20, -1.1294e-20],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.8148e-28, -1.4029e-26, -9.5221e-27, -5.0419e-29],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.5334e-27,  5.0479e-25,  3.4203e-25,  1.8950e-27],\n",
      "        [-5.6393e-29, -2.7836e-29, -2.8849e-27, -1.1805e-29],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.5234e-20, -2.7281e-18, -1.8562e-18, -9.3865e-21],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.2470e-30,  9.6136e-29,  1.7193e-28,  1.1488e-30],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4987e-32,  3.7925e-32,  1.2787e-30,  7.2966e-35],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.5905e-31, -8.0108e-30, -1.3320e-29, -5.1357e-33],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7349e-38, -1.4530e-39, -8.8760e-37, -3.6326e-41],\n",
      "        [ 1.4998e-36,  1.5905e-35,  7.6109e-35,  3.6518e-37],\n",
      "        [-3.4186e-34, -2.8984e-35, -1.7490e-32, -7.2110e-37],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.8397e-17,  5.7262e-18,  3.4992e-15,  1.4316e-19],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.5760e-30, -7.1827e-31, -4.3875e-28, -1.7957e-32],\n",
      "        [ 2.0520e-38,  7.4795e-37,  1.0890e-36,  7.4201e-39],\n",
      "        [ 8.4703e-19,  2.6193e-17,  4.3554e-17,  1.6792e-20],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3157e-13,  1.1019e-14,  6.7311e-12,  2.7548e-16],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.7145e-39,  5.9605e-37,  4.0386e-37,  2.2373e-39],\n",
      "        [-2.1513e-29, -7.6905e-30, -1.1123e-27, -3.5214e-30],\n",
      "        [-5.2251e-36, -4.0371e-34, -2.7354e-34, -1.5155e-36],\n",
      "        [-3.3631e-44, -2.8026e-45, -1.7124e-42,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3023e-25,  5.9835e-23,  6.6528e-24,  8.2419e-25],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.6972e-21,  1.4215e-22,  8.6832e-20,  3.5537e-24],\n",
      "        [ 2.5183e-15,  2.1944e-16,  1.2884e-13,  5.4685e-18],\n",
      "        [-1.0130e-28, -1.0742e-27, -5.1403e-27, -2.4664e-29],\n",
      "        [ 2.7306e-30,  3.2486e-30,  1.3958e-28,  7.5005e-32],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.7739e-23,  1.2745e-20,  1.4171e-21,  1.7555e-22],\n",
      "        [ 4.9045e-44,  3.7947e-42,  2.5714e-42,  1.4013e-44],\n",
      "        [-4.3977e-33, -1.3599e-31, -2.2613e-31, -8.7185e-35],\n",
      "        [-1.3127e-29, -1.0203e-27, -6.9656e-28, -3.4378e-30],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.1116e-17,  1.8891e-14,  2.1004e-15,  2.6021e-16],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5457e-22,  1.2770e-23,  7.9078e-21,  3.1961e-25],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.2127e-29, -2.3464e-28, -1.1228e-27, -5.3874e-30],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.5184e-31,  2.3440e-28,  3.8775e-29,  3.0039e-30],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.3330e-21, -2.0745e-22, -1.1936e-19, -5.1614e-24],\n",
      "        [ 1.0582e-25,  8.8623e-27,  5.4136e-24,  2.2156e-28],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.5354e-31, -3.7985e-32, -2.3203e-29, -9.4962e-34],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.7312e-17,  2.8963e-16,  1.3859e-15,  6.6500e-18],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.8666e-30, -2.4009e-31, -1.4666e-28, -6.0021e-33],\n",
      "        [-1.0685e-18, -4.9468e-19, -5.4651e-17, -1.1535e-20],\n",
      "        [ 1.0818e-42,  1.1468e-41,  5.4876e-41,  2.6344e-43],\n",
      "        [-1.7535e-27, -1.5478e-28, -8.9708e-26, -3.8532e-30],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.4097e-21,  1.4949e-20,  7.1535e-20,  3.4324e-22],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.5562e-19,  2.0204e-17,  1.9273e-17,  3.1899e-20],\n",
      "        [-2.2036e-18, -1.8456e-19, -1.1274e-16, -4.6140e-21],\n",
      "        [ 4.2141e-34,  4.4033e-33,  2.1387e-32,  1.0110e-34],\n",
      "        [ 8.6432e-19,  1.8654e-19,  4.4215e-17,  4.4288e-21],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.7870e-22,  2.3342e-23,  1.4258e-20,  5.8354e-25],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.1038e-24, -3.4371e-25, -2.0995e-22, -8.5926e-27],\n",
      "        [-1.7963e-26, -1.5044e-27, -9.1900e-25, -3.7611e-29],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.1953e-29, -2.3870e-26, -2.6540e-27, -3.2880e-28],\n",
      "        [ 2.2256e-21,  1.8640e-22,  1.1386e-19,  4.6600e-24],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.2914e-12, -3.4904e-11, -1.6702e-10, -8.0139e-13],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.4101e-33, -1.1073e-30, -1.2312e-31, -1.5253e-32],\n",
      "        [-1.1408e-36, -9.5545e-38, -5.8364e-35, -2.3886e-39],\n",
      "        [ 2.5970e-24,  2.1750e-25,  1.3286e-22,  5.4376e-27],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0130e-28, -1.0742e-27, -5.1403e-27, -2.4664e-29],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.3886e-21, -5.0769e-20, -7.3642e-20, -4.6750e-22],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.1702e-24, -1.2479e-23, -5.9376e-23, -2.8652e-25],\n",
      "        [-5.6414e-29, -4.7253e-30, -2.8862e-27, -1.1813e-31],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3108e-14,  1.9354e-15,  1.1822e-12,  4.8384e-17],\n",
      "        [-6.1986e-23, -3.5068e-21, -3.3586e-21, -5.7412e-24],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0367e-20,  8.6899e-22,  5.3036e-19,  2.1723e-23],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])>\n",
      "===========\n",
      "gradient:\n",
      "----------\n",
      "<bound method Tensor.norm of tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.2404e-34,\n",
      "          0.0000e+00,  3.2404e-34],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.1095e-29,\n",
      "          0.0000e+00, -5.1095e-29],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.4078e-44,  0.0000e+00,  ..., -8.6821e-22,\n",
      "          5.6472e-43, -8.6822e-22],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])>\n",
      "===========\n",
      "gradient:\n",
      "----------\n",
      "<bound method Tensor.norm of tensor([-3.3248e-34,  0.0000e+00,  5.1095e-29,  4.1165e-29, -5.7490e-29,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.6408e-39,  0.0000e+00,  0.0000e+00,  2.6323e-16,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.8455e-19, -7.0872e-35,  4.1110e-25,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         6.2990e-21, -1.2998e-25,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -2.1712e-27,  0.0000e+00,  2.8559e-21,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2666e-26,  0.0000e+00,\n",
      "        -2.5706e-17, -1.3727e-22,  0.0000e+00, -1.5545e-29,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5932e-28,\n",
      "        -4.7248e-30,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -3.0159e-21,  0.0000e+00,  0.0000e+00,  2.7638e-31,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.0935e-33,  0.0000e+00, -2.1861e-32,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4530e-39,\n",
      "         1.1467e-37, -2.8631e-35,  0.0000e+00,  0.0000e+00,  5.7284e-18,\n",
      "         0.0000e+00,  0.0000e+00, -7.1825e-31,  1.7353e-39,  7.1480e-20,\n",
      "         0.0000e+00,  0.0000e+00,  1.1019e-14,  0.0000e+00,  0.0000e+00,\n",
      "         6.6043e-40, -1.8061e-30, -4.4732e-37, -2.8026e-45,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0018e-26,  0.0000e+00,\n",
      "         0.0000e+00,  1.4215e-22,  2.1091e-16, -7.7445e-30,  2.2660e-31,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1338e-24,  4.2039e-45,\n",
      "        -3.7112e-34, -1.1197e-30,  0.0000e+00,  0.0000e+00,  3.1628e-18,\n",
      "         0.0000e+00,  1.2945e-23,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.6916e-30,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0357e-32,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.9538e-22,  8.8622e-27,  0.0000e+00, -3.7985e-32,\n",
      "         0.0000e+00,  2.0881e-18,  0.0000e+00, -2.4009e-31, -8.9210e-20,\n",
      "         8.2677e-44, -1.4685e-28,  0.0000e+00,  1.0778e-22,  0.0000e+00,\n",
      "         0.0000e+00,  2.8999e-20, -1.8456e-19,  3.2264e-35,  7.2310e-20,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3342e-23,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -3.4370e-25, -1.5044e-27,  0.0000e+00,\n",
      "        -3.9964e-30,  1.8640e-22,  0.0000e+00,  0.0000e+00, -2.5164e-13,\n",
      "         0.0000e+00,  0.0000e+00, -1.8539e-34, -9.5543e-38,  2.1750e-25,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.7445e-30,  0.0000e+00,\n",
      "         0.0000e+00, -1.1735e-22,  0.0000e+00,  0.0000e+00, -8.9413e-26,\n",
      "        -4.7248e-30,  0.0000e+00,  0.0000e+00,  1.9354e-15, -5.0569e-24,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.6822e-22,  0.0000e+00])>\n",
      "===========\n",
      "gradient:\n",
      "----------\n",
      "<bound method Tensor.norm of tensor([-3.3248e-34,  0.0000e+00,  5.1095e-29,  4.1165e-29, -5.7490e-29,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.6408e-39,  0.0000e+00,  0.0000e+00,  2.6323e-16,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.8455e-19, -7.0872e-35,  4.1110e-25,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         6.2990e-21, -1.2998e-25,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -2.1712e-27,  0.0000e+00,  2.8559e-21,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2666e-26,  0.0000e+00,\n",
      "        -2.5706e-17, -1.3727e-22,  0.0000e+00, -1.5545e-29,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5932e-28,\n",
      "        -4.7248e-30,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -3.0159e-21,  0.0000e+00,  0.0000e+00,  2.7638e-31,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.0935e-33,  0.0000e+00, -2.1861e-32,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4530e-39,\n",
      "         1.1467e-37, -2.8631e-35,  0.0000e+00,  0.0000e+00,  5.7284e-18,\n",
      "         0.0000e+00,  0.0000e+00, -7.1825e-31,  1.7353e-39,  7.1480e-20,\n",
      "         0.0000e+00,  0.0000e+00,  1.1019e-14,  0.0000e+00,  0.0000e+00,\n",
      "         6.6043e-40, -1.8061e-30, -4.4732e-37, -2.8026e-45,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0018e-26,  0.0000e+00,\n",
      "         0.0000e+00,  1.4215e-22,  2.1091e-16, -7.7445e-30,  2.2660e-31,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1338e-24,  4.2039e-45,\n",
      "        -3.7112e-34, -1.1197e-30,  0.0000e+00,  0.0000e+00,  3.1628e-18,\n",
      "         0.0000e+00,  1.2945e-23,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.6916e-30,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0357e-32,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.9538e-22,  8.8622e-27,  0.0000e+00, -3.7985e-32,\n",
      "         0.0000e+00,  2.0881e-18,  0.0000e+00, -2.4009e-31, -8.9210e-20,\n",
      "         8.2677e-44, -1.4685e-28,  0.0000e+00,  1.0778e-22,  0.0000e+00,\n",
      "         0.0000e+00,  2.8999e-20, -1.8456e-19,  3.2264e-35,  7.2310e-20,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3342e-23,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -3.4370e-25, -1.5044e-27,  0.0000e+00,\n",
      "        -3.9964e-30,  1.8640e-22,  0.0000e+00,  0.0000e+00, -2.5164e-13,\n",
      "         0.0000e+00,  0.0000e+00, -1.8539e-34, -9.5543e-38,  2.1750e-25,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.7445e-30,  0.0000e+00,\n",
      "         0.0000e+00, -1.1735e-22,  0.0000e+00,  0.0000e+00, -8.9413e-26,\n",
      "        -4.7248e-30,  0.0000e+00,  0.0000e+00,  1.9354e-15, -5.0569e-24,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  8.6822e-22,  0.0000e+00])>\n",
      "===========\n",
      "gradient:\n",
      "----------\n",
      "<bound method Tensor.norm of tensor([[-1.5364e-32, -3.6095e-21,  6.5364e-26,  2.2275e-01,  7.5341e-28,\n",
      "          0.0000e+00,  3.1073e-17, -2.2275e-01,  3.3933e-29, -4.8732e-18,\n",
      "         -1.2971e-36, -1.2791e-27,  0.0000e+00, -3.3327e-14, -1.6964e-01,\n",
      "          0.0000e+00,  1.6964e-01,  2.5795e-18,  4.5919e-33,  8.3165e-19,\n",
      "          2.2275e-01,  2.2275e-01,  1.6964e-01,  3.1782e-22, -2.3822e-44,\n",
      "          3.2168e-19, -1.6238e-24,  2.3494e-22,  8.6408e-26,  2.2275e-01,\n",
      "         -2.2275e-01,  1.5360e-21,  6.2518e-26,  2.2275e-01, -4.6123e-12,\n",
      "          0.0000e+00,  2.2275e-01, -2.2275e-01,  2.5924e-36, -2.7765e-24,\n",
      "          9.3170e-16, -1.6964e-01, -1.6964e-01,  2.1021e-28,  1.6964e-01,\n",
      "         -2.2275e-01,  1.3245e-28,  0.0000e+00,  9.2457e-01, -8.4804e-25,\n",
      "          4.1071e-29,  4.5897e+00, -2.2275e-01, -1.8627e-13,  9.2457e-01,\n",
      "          3.6652e+00,  1.6964e-01, -2.2275e-01,  2.6452e-20, -2.2275e-01]])>\n",
      "===========\n",
      "gradient:\n",
      "----------\n",
      "<bound method Tensor.norm of tensor([0.2227])>\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print('===========\\ngradient:\\n----------\\n{}'.format(p.grad.norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.grad.abs().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using best model in validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RNN_module(hidden_size = hidden_size, input_size = dim_size,\n",
    "                     output_size = number_of_classes, num_layers = 1)\n",
    "\n",
    "checkpoint = torch.load(BEST_PATH)\n",
    "print(f'Model type: {best_model}')\n",
    "print(f'Best performing model found at {checkpoint[\"epoch\"]}Âºepoch')\n",
    "\n",
    "best_model.load_state_dict(state_dict=checkpoint['model_state'], strict=True)\n",
    "best_model.eval()\n",
    "\n",
    "test_loop(test_dataloader=test_dataloader, model=best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./models_parameters/LSTM/checkpoints_2/model_1.pth')\n",
    "\n",
    "a = checkpoint['model_state']\n",
    "\n",
    "checkpoint = torch.load('./models_parameters/LSTM/checkpoints_2/model_10.pth')\n",
    "\n",
    "b = checkpoint['model_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('Quant-Trader')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc0d1250504fb5812c35f9d788d06f80c95c7322289624d7d7f522231bf576a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
